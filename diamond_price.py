# -*- coding: utf-8 -*-
"""diamond price

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Yit13QgCjbUEEN68mql6-bOT04fYtozs

# **GetThe Data**
"""

# Commented out IPython magic to ensure Python compatibility.
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
# %matplotlib inline

from google.colab import files
uploaded=files.upload()

"""#**EDA**"""

diamond=pd.read_csv('train_set.csv')

diamond.head()

diamond.info()

diamond.describe()

diamond.drop(['Id'],axis=1,inplace=True)

#We observe that minmum value of x, y and z is zero so we need to delete them
diamond=diamond.loc[(diamond[['x','y','z']]!=0).all(axis=1)]

diamond.describe()

#make sure that there is no null values
diamond.isna().sum()

#make sure there is no duplicated valus
diamond.duplicated().sum()

# delete duplicated rows
diamond=diamond.drop_duplicates()

diamond.duplicated().sum()

"""# **VisualizaingThe Data**"""

diamond.hist(figsize=(20,15),bins=50)
plt.show()

diamond['price'].plot(kind='box')

diamond[['y','x','z','carat','depth','table']].plot(kind='box')

"""we can see that there are outliers so we should get rid of them"""

#dropping outliers
cols=['y','x','z','carat','depth','table']
Q1=diamond[cols].quantile(0.25)
Q3=diamond[cols].quantile(0.75)
IQR=Q3-Q1
diamond=diamond[~((diamond[cols]<(Q1-1.5*IQR))|(diamond[cols]>(Q3+1.5*IQR))).any(axis=1)]

corr_matrix = diamond.corr()
corr_matrix['price'].sort_values(ascending = False)

diamond[['clarity']].value_counts()

diamond[['color']].value_counts()

diamond[['cut']].value_counts()

"""#Create a Test Set"""

from sklearn.model_selection import train_test_split
train_set, test_set = train_test_split(diamond, test_size=0.2,
random_state=42)

diamond["carat_cat"] = pd.cut(diamond["carat"],
 bins=[0., 0.5, 1.0, 1.5, 2., np.inf],
 labels=[1, 2, 3, 4, 5])

diamond["carat_cat"].value_counts().sort_index().plot.bar(rot=0,
grid=True)
plt.xlabel("Carat category")
plt.ylabel("Number of diamonds")
plt.show()

strat_train_set, strat_test_set = train_test_split(
 diamond, test_size=0.2, stratify=diamond["carat_cat"],
random_state=42)

for set_ in (strat_train_set, strat_test_set):
 set_.drop("carat_cat", axis=1, inplace=True)

diamond= strat_train_set.copy()

sns.boxplot(x='price',y='cut',data=diamond)

sns.boxplot(x='price',y='color',data=diamond)

sns.boxplot(x='price',y='clarity',data=diamond)

from pandas.plotting import scatter_matrix


scatter_matrix(diamond, figsize=(12, 8))

plt.show()

sns.heatmap(diamond.corr(),cmap='YlGnBu',annot=True)

"""# Prepare the Data for Machine Learning Algorithms

adding new feature(length_to_width)
"""

diamond["length_to_width"] = diamond["x"] / diamond["y"]

diamond

diamond = strat_train_set.drop("price", axis=1)
diamond_labels = strat_train_set["price"].copy()

diamond["length_to_width"] = diamond["x"] / diamond["y"]

diamond_num = diamond[['table','carat','depth','x','y','z','length_to_width']]

diamond_cat = diamond[["cut",'color','clarity']]
diamond_cat.head()

from sklearn.preprocessing import OrdinalEncoder

from sklearn.pipeline import Pipeline

from sklearn.preprocessing import StandardScaler

from sklearn.compose import ColumnTransformer
num_col=list(diamond_num)
cat_col=list(diamond[['cut','color','clarity']])

num_pipeline=Pipeline([("standardize", StandardScaler()),])
cat_pipeline=Pipeline([('Ordinally',OrdinalEncoder()),])

full_pipeline=ColumnTransformer([
 ("num", num_pipeline, num_col),
 ("cat", cat_pipeline, cat_col),])

diamond=strat_train_set.copy()
diamond['length_to_width']=diamond['x']/diamond['y']

diamond.isna().sum()

med=diamond['length_to_width'].median()

diamond['length_to_width'].fillna(med,inplace=True)

diamond.isna().sum()

diamond=full_pipeline.fit_transform(diamond)

"""# Select and Train a Model"""

from sklearn.linear_model import LinearRegression

lin_reg = LinearRegression()
lin_reg.fit(diamond,diamond_labels)

from sklearn.metrics import mean_squared_error

diamond_predictions = lin_reg.predict(diamond)
lin_mse = mean_squared_error(diamond_labels, diamond_predictions)
lin_rmse = np.sqrt(lin_mse)
print(lin_rmse)

from sklearn.tree import DecisionTreeRegressor

tree_reg = DecisionTreeRegressor(random_state = 42)
tree_reg.fit(diamond,diamond_labels)

diamond_predictions = tree_reg.predict(diamond)
tree_mse = mean_squared_error(diamond_labels,diamond_predictions)
tree_rmse = np.sqrt(tree_mse)
tree_rmse

"""**Cross Validation**"""

from sklearn.model_selection import cross_val_score

scores = cross_val_score(tree_reg, diamond, diamond_labels, scoring ="neg_mean_squared_error",cv = 10)
tree_rmse_scores = np.sqrt(-scores)

print("Scores: ", tree_rmse_scores)
print("Mean: ", tree_rmse_scores.mean())
print("Standard Deviation: ", tree_rmse_scores.std())

scores = cross_val_score(lin_reg, diamond, diamond_labels, scoring ="neg_mean_squared_error",cv = 10)
lin_rmse_scores = np.sqrt(-scores)

print("Scores: ", lin_rmse_scores)
print("Mean: ", lin_rmse_scores.mean())
print("Standard Deviation: ", lin_rmse_scores.std())

from sklearn.ensemble import RandomForestRegressor
forest_reg = RandomForestRegressor()
forest_scores = cross_val_score(forest_reg,diamond, diamond_labels,scoring = "neg_mean_squared_error", cv = 10)
forest_rmse_scores = np.sqrt(-forest_scores)

print("Scores: ", forest_rmse_scores)
print("Mean: ", forest_rmse_scores.mean())
print("Standard Deviation: ", forest_rmse_scores.std())

strat_test_set['length_to_width']=strat_test_set["x"] / strat_test_set["y"]

strat_test_set.isna().sum()

tmed=strat_test_set['length_to_width'].median()

strat_test_set['length_to_width'].fillna(tmed,inplace=True)

strat_test_set.isna().sum()

x_test = strat_test_set.drop("price", axis=1)
y_test = strat_test_set["price"].copy()

test_cat_col =list(x_test[['cut','color','clarity']])
test_num_col =list(x_test[['table','carat','depth','x','y','z','length_to_width']])

tnum_pipeline=Pipeline([("standardize", StandardScaler()),])
tcat_pipeline=Pipeline([('Ordinally',OrdinalEncoder()),])

tfull_pipeline=ColumnTransformer([
 ("tnum", tnum_pipeline, test_num_col),
 ("tcat", tcat_pipeline, test_cat_col),])

test_set=tfull_pipeline.fit_transform(x_test)

forest_reg.fit(diamond,diamond_labels)
predications=forest_reg.predict(test_set)

forest_mse = mean_squared_error(y_test,predications)
forest_rmse = np.sqrt(forest_mse)
forest_rmse

tree_reg.fit(diamond,diamond_labels)
predications2=tree_reg.predict(test_set)

tree_mse = mean_squared_error(y_test,predications2)
tree_rmse = np.sqrt(tree_mse)
tree_rmse

lin_reg.fit(diamond,diamond_labels)

predictions3 = lin_reg.predict(test_set)
lin_mse = mean_squared_error(y_test,predictions3)
lin_rmse = np.sqrt(lin_mse)
print(lin_rmse)

"""It seems that random forest is the best model

# Applying the choosen model on test_set
"""

# load test set
uploaded=files.upload()

test=pd.read_csv('test_set.csv')

test.head()

test['length_to_width']=test['x']/test['y']

test.drop('Id',axis=1,inplace=True)

test.head()

test.isna().sum()

medt=test['length_to_width'].median()
test['length_to_width'].fillna(medt,inplace=True)

test=full_pipeline.fit_transform(test)

forest_reg.fit(diamond,diamond_labels)
tpredications=forest_reg.predict(test)

test=pd.read_csv('test_set.csv')

submission=test[['Id']]
submission

submission['price']=predications

submission.to_csv('submission.csv',index=None)